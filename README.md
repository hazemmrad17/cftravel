# ASIA.fr Travel Agent

A hybrid PHP/Symfony + Python/FastAPI travel chat application with AI-powered travel recommendations.

## ğŸš€ Features

- **AI-Powered Chat**: Real-time conversation with ASIA.fr Agent using Groq LLM
- **Travel Recommendations**: Intelligent offer matching based on user preferences
- **Streaming Responses**: Real-time character-by-character response streaming
- **Hybrid Architecture**: Symfony frontend with Python AI backend
- **Modern UI**: Responsive chat interface with offer cards

## ğŸ—ï¸ Architecture

```
â”œâ”€â”€ public/                 # Symfony public assets
â”‚   â””â”€â”€ assets/js/         # Frontend JavaScript
â”œâ”€â”€ src/                   # Symfony PHP code
â”‚   â””â”€â”€ Controller/        # PHP controllers
â”œâ”€â”€ cftravel_py/          # Python AI backend
â”‚   â”œâ”€â”€ api/              # FastAPI server
â”‚   â”œâ”€â”€ core/             # Configuration and constants
â”‚   â”œâ”€â”€ models/           # Data models
â”‚   â”œâ”€â”€ pipelines/        # AI processing pipelines
â”‚   â”œâ”€â”€ services/         # Business logic services
â”‚   â””â”€â”€ data/             # Travel data
â””â”€â”€ templates/            # Symfony templates
```

## ğŸ› ï¸ Technology Stack

### Frontend
- **Symfony 6**: PHP framework
- **JavaScript**: Vanilla JS with modern ES6+ features
- **CSS**: Modern styling with responsive design

### Backend
- **Python 3.11+**: Core AI logic
- **FastAPI**: High-performance API framework
- **Groq**: LLM provider for AI responses
- **Sentence Transformers**: Text embeddings

## ğŸ“‹ Prerequisites

- PHP 8.1+
- Python 3.11+
- Composer
- Node.js (for asset compilation)

## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone <your-repo-url>
cd cftravel3
```

### 2. Install Dependencies

#### PHP/Symfony
```bash
composer install
```

#### Python
```bash
cd cftravel_py
pip install -r requirements.txt
```

### 3. Environment Setup

Create a `.env` file in the root directory:
```env
# Groq API Configuration
GROQ_API_KEY=your_groq_api_key_here

# Model Configuration
REASONING_MODEL=openai/gpt-oss-120b
GENERATION_MODEL=llama-3.1-8b-instant
MATCHER_MODEL=llama-3.1-8b-instant
EXTRACTOR_MODEL=llama-3.1-8b-instant

# API Configuration
AGENT_API_URL=http://localhost:8001
```

### 4. Start the Servers

#### Start Python AI Backend (Port 8001)
```bash
python -m uvicorn cftravel_py.api.server:app --host 0.0.0.0 --port 8001
```

#### Start Symfony Frontend (Port 8000)
```bash
# Option 1: Symfony CLI
symfony server:start -d --port=8000

# Option 2: PHP built-in server
php -S localhost:8000 -t public
```

### 5. Access the Application

Open your browser and go to: **http://localhost:8000**

## ğŸ¯ Usage

1. **Start a Conversation**: Type your travel preferences
2. **Get AI Recommendations**: Receive personalized travel offers
3. **Explore Offers**: View detailed travel packages with pricing
4. **Manage Preferences**: Update your travel preferences anytime

## ğŸ”§ Configuration

### AI Models
The application uses multiple AI models for different tasks:
- **Orchestrator**: Makes conversation decisions
- **Generator**: Creates natural responses
- **Matcher**: Matches offers to preferences
- **Extractor**: Extracts user preferences

### Environment Variables

#### Required
- `GROQ_API_KEY`: Your Groq API key

#### Model Configuration (Optional - uses defaults if not set)
- `REASONING_MODEL`: Model for orchestration (default: openai/gpt-oss-120b)
- `GENERATION_MODEL`: Model for response generation (default: llama-3.1-8b-instant)
- `MATCHER_MODEL`: Model for offer matching (default: llama-3.1-8b-instant)
- `EXTRACTOR_MODEL`: Model for preference extraction (default: llama-3.1-8b-instant)
- `EMBEDDING_MODEL`: Embedding model for semantic search (default: all-MiniLM-L6-v2)

#### Model Parameters (Optional - uses defaults if not set)
- `REASONING_TEMPERATURE`: Temperature for reasoning model (default: 0.1)
- `GENERATION_TEMPERATURE`: Temperature for generation model (default: 0.7)
- `MATCHER_TEMPERATURE`: Temperature for matching model (default: 0.3)
- `EXTRACTOR_TEMPERATURE`: Temperature for extraction model (default: 0.1)
- `REASONING_MAX_TOKENS`: Max tokens for reasoning model (default: 2048)
- `GENERATION_MAX_TOKENS`: Max tokens for generation model (default: 2048)
- `MATCHER_MAX_TOKENS`: Max tokens for matching model (default: 2048)
- `EXTRACTOR_MAX_TOKENS`: Max tokens for extraction model (default: 1024)

#### API Configuration (Optional - uses defaults if not set)
- `GROQ_BASE_URL`: Groq API base URL (default: https://api.groq.com/openai/v1)
- `AGENT_API_URL`: Internal API URL (default: http://localhost:8001)

#### Other Settings (Optional)
- `DEBUG`: Enable debug mode (default: false)
- `DATA_PATH`: Path to travel data (default: ./cftravel_py/data)

## ğŸ“ Project Structure

```
cftravel3/
â”œâ”€â”€ public/                 # Web assets
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ js/
â”‚           â””â”€â”€ chat.js     # Main chat interface
â”œâ”€â”€ src/
â”‚   â””â”€â”€ Controller/
â”‚       â””â”€â”€ ChatController.php  # PHP API endpoints
â”œâ”€â”€ cftravel_py/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ server.py       # FastAPI server
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py       # Configuration
â”‚   â”‚   â””â”€â”€ constants.py    # Constants
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ data_models.py  # Request/response models
â”‚   â”‚   â””â”€â”€ response_models.py
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â””â”€â”€ concrete_pipeline.py  # AI processing
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ data_service.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”œâ”€â”€ memory_service.py
â”‚   â”‚   â””â”€â”€ offer_service.py
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ travel_offers/  # Travel data
â”œâ”€â”€ templates/              # Symfony templates
â”œâ”€â”€ composer.json           # PHP dependencies
â”œâ”€â”€ package.json            # Node.js dependencies
â””â”€â”€ README.md              # This file
```

## ğŸ”Œ API Endpoints

### Python Backend (Port 8001)
- `GET /health` - Health check
- `POST /chat` - Send message
- `POST /chat/stream` - Streaming chat
- `GET /status` - Agent status
- `GET /welcome` - Welcome message
- `POST /memory/clear` - Clear conversation memory
- `GET /preferences` - Get user preferences
- `POST /preferences` - Update preferences
- `DELETE /preferences` - Clear preferences

### Symfony Frontend (Port 8000)
- `GET /` - Main chat interface
- `POST /chat/message` - Forward to Python API
- `POST /chat/stream` - Forward streaming
- `POST /chat/memory/clear` - Forward memory clear

## ğŸ§ª Testing

### Test Python API
```bash
cd cftravel_py
python -m pytest tests/
```

### Test Frontend
```bash
# Open browser and test chat functionality
# Send test messages and verify responses
```

## ğŸš€ Deployment

### Production Setup
1. Set up proper environment variables
2. Configure web server (Nginx/Apache)
3. Set up SSL certificates
4. Configure database if needed
5. Set up monitoring and logging

### Docker (Optional)
```bash
# Build and run with Docker Compose
docker-compose up -d
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support and questions:
- Create an issue in the repository
- Check the documentation
- Review the code comments

## ğŸ”„ Version History

- **v1.0.0**: Initial release with AI-powered travel chat
- **v1.1.0**: Added streaming responses and offer matching
- **v1.2.0**: Enhanced UI and preference management

---

**Made with â¤ï¸ for ASIA.fr** 