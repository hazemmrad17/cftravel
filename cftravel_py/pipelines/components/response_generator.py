"""
Response Generator Component for ASIA.fr Agent
Handles text generation and response formatting
"""

import json
from typing import Dict, Any, List
from ..core import PipelineComponent, PipelineContext, PipelineState
from services.llm_service import LLMService
from services.memory_service import MemoryService

class ResponseGeneratorComponent(PipelineComponent):
    """Generates intelligent responses based on pipeline context"""
    
    def __init__(self, llm_service: LLMService, memory_service: MemoryService):
        super().__init__("ResponseGenerator", priority=70)
        self.llm_service = llm_service
        self.memory_service = memory_service
    
    def is_required(self, context: PipelineContext) -> bool:
        """Always required to generate a response"""
        return True
    
    async def process(self, context: PipelineContext) -> PipelineContext:
        """Generate appropriate response based on context"""
        try:
            # Determine response type and generate accordingly
            response_type = context.get_metadata('response_type', 'question')
            intent = context.get_metadata('intent', 'general')
            
            if intent == 'greeting':
                # Handle greetings, thanks, and goodbyes naturally
                response = await self._generate_natural_response(context, "greeting")
            elif intent == 'preference_complete':
                # Generate text-based preference summary
                response = await self._generate_preference_summary_response(context)
            elif intent == 'confirmation':
                # User confirmed preferences - ensure offers are generated first
                context.add_metadata('should_show_offers', True)
                # The recommendation engine will be called by the pipeline to generate offers
                response = await self._generate_natural_response(context, "confirmation")
            elif intent == 'modification':
                # User wants to modify preferences - help them naturally
                response = await self._generate_natural_response(context, "modification")
            elif intent == 'suggestion_request':
                # User wants AI suggestions - provide helpful recommendations
                response = await self._generate_natural_response(context, "suggestion")
            elif intent == 'recommendation_request':
                # User wants specific recommendations - provide intelligent suggestions
                response = await self._generate_natural_response(context, "recommendation")
            elif intent == 'vague_question':
                # User asks vague questions - ask for clarification
                response = await self._generate_natural_response(context, "clarification")
            elif intent == 'information_request':
                # User wants general travel information
                response = await self._generate_natural_response(context, "information")
            elif intent == 'new_search':
                # User wants to start a new search
                response = await self._generate_natural_response(context, "new_search")
            elif intent == 'general':
                # General conversation - respond naturally
                response = await self._generate_natural_response(context, "conversation")
            elif context.get_metadata('should_show_offers', False):
                # Check if offers are available (generated by recommendation engine)
                offers = context.get_metadata('offers', [])
                if offers:
                    # Generate offer presentation response
                    response = await self._generate_offer_response(context)
                else:
                    # Offers not ready yet, generate confirmation message
                    response = await self._generate_confirmation_response(context)
            else:
                # Generate general conversation response
                response = await self._generate_general_response(context)
            
            # Store response in context
            context.add_metadata('generated_response', response)
            context.add_metadata('response_text', response.get('text', ''))
            
            return context
            
        except Exception as e:
            self.log_error(context, e)
            # Fallback response
            context.add_metadata('generated_response', self._fallback_response())
            return context
    
    async def _generate_offer_response(self, context: PipelineContext) -> Dict[str, Any]:
        """Generate response when showing offers"""
        offers = context.get_metadata('offers', [])
        
        if not offers:
            return {
                'text': "Je n'ai pas trouvÃ© d'offres correspondant exactement Ã  vos critÃ¨res. Pouvez-vous prÃ©ciser vos prÃ©fÃ©rences ?",
                'type': 'no_offers',
                'offers': []
            }
        
        # Generate preference summary
        preference_summary = self._create_preference_summary_text(context.user_preferences)
        
        # Generate personalized introduction
        intro = await self._generate_offer_intro(context, offers)
        
        # Combine preference summary with introduction
        full_response = f"{intro}\n\nğŸ“‹ **RÃ©capitulatif de vos prÃ©fÃ©rences :**\n{preference_summary}\n\nâœ¨ Voici les offres qui correspondent parfaitement Ã  vos critÃ¨res :"
        
        return {
            'text': full_response,
            'type': 'offers',
            'offers': offers,
            'show_preference_summary': True
        }
    
    async def _generate_natural_response(self, context: PipelineContext, response_type: str) -> Dict[str, Any]:
        """Generate natural, intelligent responses using LLM"""
        try:
            # Build context-aware prompt
            prompt = self._build_natural_response_prompt(context, response_type)
            
            # Get LLM response
            messages = [{"role": "user", "content": prompt}]
            response = await self.llm_service.create_generation_completion(messages, stream=False)
            
            return {
                'text': response.strip(),
                'type': response_type,
                'should_show_offers': response_type == 'confirmation'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Natural response generation failed: {e}")
            # Fallback response
            return {
                'text': "Je suis dÃ©solÃ©, je n'ai pas bien compris. Pouvez-vous reformuler ? ğŸ˜Š",
                'type': response_type,
                'should_show_offers': False
            }
    
    def _build_natural_response_prompt(self, context: PipelineContext, response_type: str) -> str:
        """Build prompt for natural response generation"""
        user_input = context.user_input
        preferences = context.user_preferences
        conversation_history = context.conversation_history[-5:] if context.conversation_history else []
        
        # Build context string
        context_str = ""
        if preferences:
            context_str = f"\nPrÃ©fÃ©rences actuelles: {json.dumps(preferences, indent=2, ensure_ascii=False)}"
        
        history_str = ""
        if conversation_history:
            history_str = f"\nHistorique rÃ©cent: {conversation_history}"
        
        base_prompt = f"""
Tu es ASIA.fr Agent, un spÃ©cialiste du voyage en Asie avec une personnalitÃ© dÃ©contractÃ©e et amicale. Tu parles comme un ami qui connaÃ®t bien l'Asie et qui est excitÃ© de partager ses connaissances.

CONTEXTE:{context_str}{history_str}

MESSAGE UTILISATEUR: "{user_input}"

TYPE DE RÃ‰PONSE REQUISE: {response_type}

INSTRUCTIONS:
- Parle de maniÃ¨re dÃ©contractÃ©e et naturelle, comme Ã  un ami
- Sois enthousiaste et passionnÃ© par l'Asie
- Utilise un ton conversationnel, pas formel
- Pose des questions de maniÃ¨re naturelle, pas comme une interrogation
- Sois flexible et ouvert aux suggestions
- Utilise des expressions familiÃ¨res et chaleureuses
- Ã‰vite le langage trop formel ou commercial

RÃ‰PONSE:
"""
        
        # Add specific instructions based on response type
        if response_type == "greeting":
            base_prompt += "\n- Si c'est un remerciement, rÃ©ponds poliment\n- Si c'est un au revoir, sois chaleureux\n- Si c'est une salutation, propose ton aide"
        elif response_type == "modification":
            base_prompt += "\n- Aide l'utilisateur Ã  modifier ses prÃ©fÃ©rences\n- Propose des alternatives\n- Sois flexible et comprÃ©hensif\n- Rappelle les prÃ©fÃ©rences actuelles\n- Permets de modifier destination, durÃ©e, budget, style, etc."
        elif response_type == "suggestion":
            base_prompt += "\n- Propose des destinations intÃ©ressantes\n- SuggÃ¨re des expÃ©riences uniques\n- Sois crÃ©atif et inspirant\n- ConsidÃ¨re les prÃ©fÃ©rences actuelles"
        elif response_type == "recommendation":
            base_prompt += "\n- Analyse les prÃ©fÃ©rences de l'utilisateur en profondeur\n- Recommande des destinations spÃ©cifiques basÃ©es sur leurs intÃ©rÃªts\n- ConsidÃ¨re les caractÃ©ristiques des destinations (plages, montagnes, culture, etc.)\n- Sois intelligent dans les correspondances - ne fais pas juste du matching de mots-clÃ©s\n- Propose des expÃ©riences complÃ©mentaires\n- ConsidÃ¨re les facteurs saisonniers\n- Sois prÃ©cis et pertinent dans tes recommandations"
        elif response_type == "confirmation":
            base_prompt += "\n- Confirme les prÃ©fÃ©rences\n- PrÃ©pare pour l'affichage des offres\n- Sois enthousiaste"
        elif response_type == "clarification":
            base_prompt += "\n- Liste TOUTES les prÃ©fÃ©rences nÃ©cessaires en une seule fois\n- Utilise des puces (â€¢) pour chaque prÃ©fÃ©rence\n- Sois enthousiaste et encourageant\n- Propose des exemples pour chaque prÃ©fÃ©rence\n- Mentionne que le budget est optionnel\n- Ã‰vite de poser les questions une par une"
        elif response_type == "information":
            base_prompt += "\n- Fournis des informations utiles sur le voyage\n- Sois informatif et engageant\n- Propose des conseils pratiques\n- Guide vers la planification"
        elif response_type == "new_search":
            base_prompt += "\n- Aide l'utilisateur Ã  commencer une nouvelle recherche\n- Efface les prÃ©fÃ©rences prÃ©cÃ©dentes si nÃ©cessaire\n- Sois enthousiaste pour une nouvelle aventure\n- Guide vers la collecte de nouvelles prÃ©fÃ©rences"
        elif response_type == "conversation":
            base_prompt += "\n- RÃ©ponds naturellement Ã  la conversation\n- Sois utile et engageant\n- Guide vers la planification de voyage si appropriÃ©\n- Maintiens le contexte de la conversation"
        
        return base_prompt
    
    async def _generate_offer_intro(self, context: PipelineContext, offers: List[Dict]) -> str:
        """Generate personalized introduction for offers"""
        try:
            prompt = f"""
You are ASIA.fr Agent, a French travel specialist. Generate a personalized introduction for the offers you're about to present.

USER PREFERENCES: {json.dumps(context.user_preferences, indent=2, ensure_ascii=False)}
OFFER COUNT: {len(offers)}

Generate a warm, personalized introduction in French that:
1. Shows excitement about finding perfect offers for them
2. Mentions the number of offers found
3. Is friendly and enthusiastic
4. Uses emojis naturally

Keep it concise (1-2 sentences maximum).

RESPOND ONLY WITH THE INTRODUCTION TEXT:
"""
            
            messages = [{"role": "user", "content": prompt}]
            response = await self.llm_service.create_generation_completion(messages, stream=False)
            return response.strip()
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to generate offer intro: {e}")
            return f"Voici {len(offers)} offres qui correspondent parfaitement Ã  vos critÃ¨res :"
    
    async def _generate_confirmation_response(self, context: PipelineContext) -> Dict[str, Any]:
        """Generate response for user confirmations"""
        try:
            prompt = f"""
You are ASIA.fr Agent, a friendly and enthusiastic French travel specialist with a warm personality like Layla.ai. The user has confirmed their preferences and you're excited to show them amazing offers!

USER PREFERENCES: {json.dumps(context.user_preferences, indent=2, ensure_ascii=False)}

Generate a warm, enthusiastic confirmation response in French that:
1. ğŸŒŸ Acknowledges their confirmation with genuine excitement
2. âœ¨ Shows enthusiasm about preparing their personalized offers
3. Uses emojis naturally to express your happiness
4. Sounds like you're genuinely excited to help them

Keep it warm and encouraging (1-2 sentences).

RESPOND ONLY WITH THE CONFIRMATION TEXT:
"""
            
            messages = [{"role": "user", "content": prompt}]
            response = await self.llm_service.create_generation_completion(messages, stream=False)
            return {
                'text': response.strip(),
                'type': 'confirmation'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to generate confirmation response: {e}")
            return {
                'text': "Parfait ! Je prÃ©pare vos offres personnalisÃ©es.",
                'type': 'confirmation'
            }
    
    async def _generate_modification_response(self, context: PipelineContext) -> Dict[str, Any]:
        """Generate response for modification requests"""
        try:
            prompt = f"""
You are ASIA.fr Agent, a friendly and enthusiastic French travel specialist with a warm personality like Layla.ai. The user wants to modify their preferences and you're happy to help them get it perfect!

CURRENT PREFERENCES: {json.dumps(context.user_preferences, indent=2, ensure_ascii=False)}
USER INPUT: {context.user_input}

Generate a warm, helpful response in French that:
1. ğŸŒŸ Acknowledges their desire to modify preferences with understanding
2. âœ¨ Shows enthusiasm about helping them get their perfect trip
3. Asks what they'd like to change with genuine interest
4. Uses emojis naturally to keep it friendly
5. Sounds like you're genuinely happy to help them adjust

Keep it conversational, warm and encouraging.

RESPOND ONLY WITH THE MODIFICATION RESPONSE:
"""
            
            messages = [{"role": "user", "content": prompt}]
            response = await self.llm_service.create_generation_completion(messages, stream=False)
            return {
                'text': response.strip(),
                'type': 'modification'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to generate modification response: {e}")
            return {
                'text': "Bien sÃ»r ! Que souhaitez-vous modifier dans vos prÃ©fÃ©rences ?",
                'type': 'modification'
            }
    
    async def _generate_general_response(self, context: PipelineContext) -> Dict[str, Any]:
        """Generate general conversation response"""
        try:
            # Check if we need more information
            preference_count = len(context.user_preferences)
            
            if preference_count < 2:
                # Need more preferences
                prompt = f"""
You are ASIA.fr Agent, a friendly and enthusiastic French travel specialist with a warm personality like Layla.ai. You're passionate about helping people discover amazing Asian destinations and you show genuine excitement about their travel dreams.

CURRENT PREFERENCES: {json.dumps(context.user_preferences, indent=2, ensure_ascii=False)}
USER INPUT: {context.user_input}

Generate a warm, friendly response in French that:
â€¢ Uses emojis naturally to express enthusiasm and warmth ğŸŒŸâœ¨
â€¢ Acknowledges their input with genuine interest
â€¢ Lists ALL missing preferences upfront using bullet points
â€¢ Shows excitement about helping them plan their dream trip
â€¢ Uses a conversational, friendly tone like talking to a friend
â€¢ Provides helpful examples for each preference
â€¢ Makes it easy for them to provide all info at once

IMPORTANT FORMATTING RULES:
â€¢ Use bullet points (â€¢) to list all needed preferences upfront
â€¢ Add line breaks after each bullet point
â€¢ Make each bullet point on its own line
â€¢ Include relevant emojis to make it more engaging
â€¢ Keep it conversational, warm and encouraging
â€¢ List ALL necessary preferences at once to minimize questions

Example format:
"Japan, huh? Nice choice! Land of sushi, samurai, and some seriously cool tech vibes. 

To help you find the perfect trip, I need a few details:

â€¢ Destination (you've got this covered!)

â€¢ How long are you planning to stay?

â€¢ How many people are traveling?

â€¢ What kind of experience are you looking for? (culture, adventure, relaxation, etc.)

â€¢ When do you want to travel?

â€¢ Any budget in mind? (optional)

Just let me know these details and I'll find you some amazing options!"

RESPOND ONLY WITH THE RESPONSE TEXT:
"""
            else:
                # Have enough preferences - create summary and ask for confirmation
                preference_summary = self._create_preference_summary_text(context.user_preferences)
                
                prompt = f"""
You are ASIA.fr Agent, a friendly and enthusiastic French travel specialist. The user has provided travel preferences and you need to create a natural summary and ask for confirmation.

CURRENT PREFERENCES: {json.dumps(context.user_preferences, indent=2, ensure_ascii=False)}
PREFERENCE SUMMARY: {preference_summary}
USER INPUT: {context.user_input}

Generate a warm, friendly response in French that:
1. ğŸŒŸ Shows genuine enthusiasm about their travel plans
2. âœ¨ Presents the preference summary naturally
3. Uses emojis naturally to express your excitement
4. Asks for explicit confirmation before searching
5. Keeps it conversational and friendly

IMPORTANT: Always ask for confirmation before searching. Example: "Does this summary look correct so I can search for the best offers?"

RESPOND ONLY WITH THE RESPONSE TEXT:
"""
            
            messages = [{"role": "user", "content": prompt}]
            response = await self.llm_service.create_generation_completion(messages, stream=False)
            response_text = response.strip()
            
            # Return the response text directly
            if preference_count >= 2:
                return {
                    'text': response_text,
                    'type': 'general'
                }
            else:
                formatted_response = self._format_with_bullet_points(response_text)
                return {
                    'text': formatted_response,
                    'type': 'general'
                }
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to generate general response: {e}")
            return self._fallback_response()
    
    def _fallback_response(self) -> Dict[str, Any]:
        """Fallback response when generation fails"""
        return {
            'text': "Je suis dÃ©solÃ©, j'ai rencontrÃ© une difficultÃ©. Pouvez-vous reformuler votre demande ?",
            'type': 'error'
        }
    
    def _format_with_bullet_points(self, text: str) -> str:
        """Format text to ensure proper bullet points with line breaks"""
        import re
        
        # Replace "1. ", "2. ", "3. ", "4. " etc. with "â€¢ "
        text = re.sub(r'^\d+\.\s*', 'â€¢ ', text, flags=re.MULTILINE)
        
        # Split text into lines and process each line
        lines = text.split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.strip()
            if line.startswith('â€¢'):
                # This is a bullet point line
                # Ensure the bullet point content is properly formatted
                content = line[1:].strip()
                formatted_lines.append(f"â€¢ {content}")
                formatted_lines.append("")  # Add empty line after each bullet point
            elif line:
                # Regular text line
                formatted_lines.append(line)
        
        # Join lines and clean up
        result = '\n'.join(formatted_lines)
        
        # Remove multiple consecutive empty lines
        result = re.sub(r'\n{3,}', '\n\n', result)
        
        # Ensure bullet points are properly spaced
        result = re.sub(r'â€¢\s*', 'â€¢ ', result)
        
        return result.strip()
    
    async def _generate_preference_summary_response(self, context: PipelineContext) -> Dict[str, Any]:
        """Generate preference summary response"""
        offers = context.get_metadata('offers', [])
        
        # Create a detailed preference summary text
        summary_text = self._create_preference_summary_text(context.user_preferences)
        
        return {
            'text': f"J'ai bien notÃ© vos prÃ©fÃ©rences de voyage. Voici un rÃ©capitulatif de ce que j'ai compris :\n\n{summary_text}\n\nSi ces prÃ©fÃ©rences vous conviennent, je vais vous montrer les meilleures offres. Si vous souhaitez modifier quelque chose, dites-moi simplement ce que vous voulez changer.",
            'type': 'preference_summary',
            'offers': offers,
            'show_preference_summary': True
        }
    
    def _create_preference_summary_text(self, preferences: Dict[str, Any]) -> str:
        """Create a natural language summary of user preferences"""
        parts = []
        
        # Build natural language summary
        if preferences.get('destination'):
            parts.append(f"destination {preferences['destination']}")
        if preferences.get('duration'):
            parts.append(f"pour {preferences['duration']}")
        if preferences.get('group_size'):
            parts.append(f"pour {preferences['group_size']}")
        if preferences.get('travel_dates'):
            parts.append(f"en {preferences['travel_dates']}")
        if preferences.get('style'):
            parts.append(f"style {preferences['style']}")
        if preferences.get('budget_amount'):
            parts.append(f"avec un budget de {preferences['budget_amount']}â‚¬")
        
        # Create natural summary
        if parts:
            summary = f"Vous planifiez un voyage vers {', '.join(parts)}."
        else:
            summary = "Vous avez commencÃ© Ã  planifier votre voyage."
        
        return summary 